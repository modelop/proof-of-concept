{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This template shows how to set up a model for deployment to FastScore. The integration with Jupyter is one of several ways to deploy to FS but one for the most familiar for Data Scientists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with a familiar workflow: We'll import the libraries we intend to use for the model, read in the data, transform the non-numeric features, and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('synthetic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.077368</td>\n",
       "      <td>-0.574927</td>\n",
       "      <td>824</td>\n",
       "      <td>1.012205</td>\n",
       "      <td>bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.301250</td>\n",
       "      <td>-0.101516</td>\n",
       "      <td>815</td>\n",
       "      <td>0.069122</td>\n",
       "      <td>bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.202221</td>\n",
       "      <td>1.639673</td>\n",
       "      <td>5921</td>\n",
       "      <td>-10.827503</td>\n",
       "      <td>baz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.265197</td>\n",
       "      <td>-2.459763</td>\n",
       "      <td>5730</td>\n",
       "      <td>-4.570818</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.867035</td>\n",
       "      <td>-2.377990</td>\n",
       "      <td>4855</td>\n",
       "      <td>-2.559931</td>\n",
       "      <td>qux</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat_1    feat_2    id     target word\n",
       "0  0.077368 -0.574927   824   1.012205  bar\n",
       "1 -0.301250 -0.101516   815   0.069122  bar\n",
       "2 -6.202221  1.639673  5921 -10.827503  baz\n",
       "3 -0.265197 -2.459763  5730  -4.570818  foo\n",
       "4 -2.867035 -2.377990  4855  -2.559931  qux"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "              n_values=None, sparse=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.fit(train.word.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = enc.transform(train.word.values.reshape(-1,1)).toarray()\n",
    "\n",
    "columns = enc.get_feature_names().tolist()\n",
    "\n",
    "index = train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.DataFrame(array, columns = columns, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train,one_hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>word</th>\n",
       "      <th>x0_bar</th>\n",
       "      <th>x0_baz</th>\n",
       "      <th>x0_foo</th>\n",
       "      <th>x0_qux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>-0.096059</td>\n",
       "      <td>0.833390</td>\n",
       "      <td>4788</td>\n",
       "      <td>1.429653</td>\n",
       "      <td>bar</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>-2.534983</td>\n",
       "      <td>-2.297377</td>\n",
       "      <td>3081</td>\n",
       "      <td>3.675172</td>\n",
       "      <td>bar</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.750803</td>\n",
       "      <td>-0.080121</td>\n",
       "      <td>9779</td>\n",
       "      <td>9.483944</td>\n",
       "      <td>bar</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-2.197999</td>\n",
       "      <td>-2.491178</td>\n",
       "      <td>4382</td>\n",
       "      <td>-1.777044</td>\n",
       "      <td>qux</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.198267</td>\n",
       "      <td>-2.580370</td>\n",
       "      <td>9297</td>\n",
       "      <td>-5.018199</td>\n",
       "      <td>bar</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feat_1    feat_2    id    target word  x0_bar  x0_baz  x0_foo  x0_qux\n",
       "321 -0.096059  0.833390  4788  1.429653  bar     1.0     0.0     0.0     0.0\n",
       "308 -2.534983 -2.297377  3081  3.675172  bar     1.0     0.0     0.0     0.0\n",
       "22  -1.750803 -0.080121  9779  9.483944  bar     1.0     0.0     0.0     0.0\n",
       "96  -2.197999 -2.491178  4382 -1.777044  qux     0.0     0.0     0.0     1.0\n",
       "244  0.198267 -2.580370  9297 -5.018199  bar     1.0     0.0     0.0     0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train.drop(['id', 'target', 'word'], axis=1).values, train.target.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's score one sample from the test dataframe. This will help us in constructing our action function later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = enc.transform(np.array(test.word.iloc[0]).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = test.loc[:,['feat_1', 'feat_2']].iloc[0,:].values.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_test = np.concatenate([values, one_hot],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.45646326, -1.98920996,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7746752046170864"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(single_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we must serialize the fit model and fit one-hot encoder for use inside the FastScore engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('example_model.pkl', 'wb'))\n",
    "pickle.dump(enc, open('onehotenc.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To start, we import the fastscore deploy library, this will leverage the FastScore API for deploying assets and models  \n",
    "from fastscoredeploy import ipmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schemas are going to define the input and output contract of the model execution code with the data transport. We will add one each for input and output. The schemas leverage the Avro system: https://avro.apache.org/docs/1.8.1/spec.html. The cell magic command %%schema (name) at the top defines the name of the schema. The name in this command must match the name of the corresponding schema name in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema loaded and bound to example_input variable\n"
     ]
    }
   ],
   "source": [
    "%%schema example_input\n",
    "{\n",
    "    \"type\":\"record\",\n",
    "    \"name\":\"example_input\",\n",
    "    \"fields\":[\n",
    "        {\"type\":\"double\", \"name\":\"feat_1\"},\n",
    "        {\"type\":\"double\", \"name\":\"feat_2\"},\n",
    "        {\"type\":\"int\", \"name\":\"id\"},\n",
    "        {\"type\":\"string\", \"name\":\"word\"}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema loaded and bound to tagged_double variable\n"
     ]
    }
   ],
   "source": [
    "%%schema tagged_double\n",
    "{\n",
    "    \"type\":\"record\",\n",
    "    \"name\":\"tagged_double\",\n",
    "    \"fields\":[\n",
    "        {\"type\":\"int\", \"name\":\"id\"},\n",
    "        {\"type\":\"double\", \"name\":\"pred\"}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schema can also be inferred from sample data using Schema.infer, but the samples must be given as dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = train.drop(['id', 'word', 'target'], axis=1).to_dict(orient='records')[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to provide the model execution code. This code will be deployed into the engine and used to score the mode. The cell magic command %%model  at the top defines the name of the model (rfr_model). The following smart comments map the schemas to the input and outputs. Again, the names of the schemas in these smart comments _must_ match the names of the schemas in the cell magic commands above (the name after %%schema). Next, use import statements to pull in the dependencies. Since the engine is containerized, you must include these import statements again even though you included them at the beginning of the notebook. These will need to be added to the Fastscore Engine's Dockerfile and import policy if they are not included in the default engine. We have two functions that will be called to execute code. The *begin* function is run when the model is deployed; the *action* function is called when scored (data comes to the input stream). The *begin* method typically sets the model coefficents/ object to a variable to be passed to used in the action function. The *action* function scores the model and yields the output to the output stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and bound to rfr_model variable.\n"
     ]
    }
   ],
   "source": [
    "%%model rfr_model\n",
    "\n",
    "# fastscore.schema.0: example_input\n",
    "# fastscore.schema.1: tagged_double\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def begin():\n",
    "    #It's necessary to set these variables as global so they will be scoped to use in the \"action\" function.\n",
    "    global enc\n",
    "    global rfr\n",
    "    enc = pickle.load(open('onehotenc.pkl', 'rb'))\n",
    "    rfr = pickle.load(open('example_model.pkl', 'rb'))\n",
    "\n",
    "def action(x):\n",
    "    #In this example, FastScore will parse x as a Python dictionary since x is a single record.\n",
    "    ID = x['id']\n",
    "    word = x['word']\n",
    "    one_hot = enc.transform(np.array(word).reshape(-1,1)).toarray()[0].reshape(1,-1)\n",
    "    feats = np.array([x['feat_1'], x['feat_2']]).reshape(1,-1)\n",
    "    #print(one_hot.shape)\n",
    "    #print(feats.shape)\n",
    "    sample = np.concatenate([feats,one_hot], axis=1)\n",
    "    pred = rfr.predict(sample)[0]\n",
    "    yield dict(id=ID, pred=pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test that our model works before loading it into a FastScore engine by utilizing FastScore Deploy's score function. Note again that we're inputting dictionaries into our model. FastScore's default data encoding is JSON, though other encodings are supported. The print statements that have been commented out will work in the score function below. This can be an important debugging tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 5203, 'pred': -0.7746752046170864},\n",
       " {'id': 561, 'pred': 4.520553989568708},\n",
       " {'id': 8538, 'pred': -7.276442477827523},\n",
       " {'id': 7913, 'pred': 0.5999182172933331},\n",
       " {'id': 7231, 'pred': 1.0267038757192126}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_model.score(test.drop(['target'], axis=1).to_dict(orient='records')[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input $x$ to the action function will be a JSON object and typically parsed in Python as a dictionary. Another common pattern to use is to score multiple records at once. To use recordsets, use the smart-comment `#fastscore.recordset.<slot_no>` where `<slot_no>` is the slot number you want to use. The schema will be checked against each individual record in the set, but $x$ will be parsed as a Pandas DataFrame by default. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to deploy our FastScore conformed model to a FastScore engine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastscoredeploy.suite import Connect\n",
    "from base64 import b64encode\n",
    "from six.moves.urllib.parse import quote\n",
    "\n",
    "def encode(username, password):\n",
    "  if ':' in username:\n",
    "      raise FastScoreError('invalid username')\n",
    "  username_password = '%s:%s' % (quote(username), quote(password))\n",
    "  return 'Basic ' + b64encode(username_password.encode()).decode()\n",
    "\n",
    "secret = encode(\"fastscore\",\"fastscore\")\n",
    "c = Connect('https://a4dcbcd627bff11e9ae160a680e94179-1860344962.us-east-1.elb.amazonaws.com/dashboard')\n",
    "c.set_basic_auth_secret(secret)\n",
    "\n",
    "mm = c.lookup('model-manage')\n",
    "eng = c.get('engine-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we add/ update the model to Model Manage to make it avaiable for deployment\n",
    "#Returns true for updated, false when the model is the same within Model Manage\n",
    "rfr_model.update(model_manage=mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pickle files containing the trained model and trained one-hot encoder must be given to the FastScore engine as an attachment, since each model can only have one attachment, we must include them in the same tar.gz archive or zip file. Note that tar.gz and zip are the only two file formats supported by FastScore attachments. Also note that anything the model needs to run can be included in an attachment including libraries which you've developed yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar cvfz att.tar.gz example_model.pkl onehotenc.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastscore.attachment import Attachment\n",
    "\n",
    "att = Attachment('att.tar.gz', datafile='att.tar.gz')\n",
    "att.upload(rfr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we deploy to the engine. If there are errors, view the container logs for details\n",
    "rfr_model.deploy(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we score with our sample data\n",
    "eng.score(test.drop(['target'], axis=1).to_dict(orient='records')[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have tested the model locally and within the engine. It is ready to pass to model ops for promotion into UAT and futher operationalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
